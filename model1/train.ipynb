{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![model](img/model1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    实现一个简单的孪生网络，做语义相似度：\n",
    "    \n",
    "        1.从上图可看出整体的结构相对较简单，左右两边几本一致。A句和B句分别进入左右两个结构。输入到网络中是token embedding + position_embedding\n",
    "        \n",
    "        2.再经过cnn-encoder进行编码\n",
    "        \n",
    "        3.多头注意力层，self-attention的输入：一个是本句cnn-encoder的输出；一个是另一句的cnn-encoder的输出。作为两句的交互层。\n",
    "        \n",
    "        4.将cnn-encoder的输出和self-attention的输出进行cat连接\n",
    "        \n",
    "        5.接一个fc层\n",
    "        \n",
    "        6.一个平均池化层\n",
    "        \n",
    "        7.最后是用cosine余弦作相似度匹配计算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cnn-encoder结构如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![model](img/cnn-encoder.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texta</th>\n",
       "      <th>textb</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>也开不了花呗，就这样了？完事了</td>\n",
       "      <td>真的嘛？就是花呗付款</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>花呗冻结以后还能开通吗</td>\n",
       "      <td>我的条件可以开通花呗借款吗</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>如何得知关闭借呗</td>\n",
       "      <td>想永久关闭借呗</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>花呗扫码付钱</td>\n",
       "      <td>二维码扫描可以用花呗吗</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>花呗逾期后不能分期吗</td>\n",
       "      <td>我这个 逾期后还完了 最低还款 后 能分期吗</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>花呗分期清空</td>\n",
       "      <td>花呗分期查询</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>借呗逾期短信通知</td>\n",
       "      <td>如何购买花呗短信通知</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>借呗即将到期要还的账单还能分期吗</td>\n",
       "      <td>借呗要分期还，是吗</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>花呗为什么不能支付手机交易</td>\n",
       "      <td>花呗透支了为什么不可以继续用了</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>在吗，双***有临时花呗额度吗</td>\n",
       "      <td>花呗临时额度到时间怎么办</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              texta                   textb  label\n",
       "0   也开不了花呗，就这样了？完事了              真的嘛？就是花呗付款      0\n",
       "1       花呗冻结以后还能开通吗           我的条件可以开通花呗借款吗      0\n",
       "2          如何得知关闭借呗                 想永久关闭借呗      0\n",
       "3            花呗扫码付钱             二维码扫描可以用花呗吗      0\n",
       "4        花呗逾期后不能分期吗  我这个 逾期后还完了 最低还款 后 能分期吗      0\n",
       "5            花呗分期清空                  花呗分期查询      0\n",
       "6          借呗逾期短信通知              如何购买花呗短信通知      0\n",
       "7  借呗即将到期要还的账单还能分期吗               借呗要分期还，是吗      0\n",
       "8     花呗为什么不能支付手机交易         花呗透支了为什么不可以继续用了      0\n",
       "9   在吗，双***有临时花呗额度吗            花呗临时额度到时间怎么办      0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "data_path = os.getcwd()\n",
    "file_path = os.path.join(data_path, 'data', 'rawdata.csv')\n",
    "\n",
    "pd_csv = pd.read_csv(file_path, sep='\t', names=['texta', 'textb', 'label'])\n",
    "# pd_csv.drop('id', axis=1, inplace=True)\n",
    "pd_csv.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset load done!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchtext import data,datasets\n",
    "from torchtext.data import Iterator, BucketIterator\n",
    "from torchtext.vocab import Vectors\n",
    "from torch import nn,optim\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def tokenize(x):\n",
    "    x = x.strip().replace(' ','')\n",
    "    sentences = re.sub(\"[.。，“”,!?\\\\-]\", '', x.lower()) # 去除特殊符号\n",
    "    return list(sentences)\n",
    "\n",
    "TEXT = data.Field(\n",
    "                    sequential=True,\n",
    "                    tokenize=tokenize,\n",
    "                    lower=False,\n",
    "                    use_vocab=True,\n",
    "                    pad_token='<pad>',\n",
    "                    unk_token='<unk>',\n",
    "                    batch_first=True,\n",
    "                    fix_length=30)\n",
    "\n",
    "LABEL = data.Field(\n",
    "                    sequential=False,\n",
    "                    use_vocab=False,\n",
    "                    batch_first=True)\n",
    "\n",
    "\n",
    "# 获取训练或测试数据集\n",
    "def get_dataset(csv_data, text_field, label_field, test=False):\n",
    "    fields = [('id', None), ('texta', text_field), ('textb', text_field), ('label', label_field)]\n",
    "    examples = []\n",
    "    if test: #测试集，不加载label\n",
    "        for texta, textb in zip(csv_data['texta'], csv_data['textb']):\n",
    "            examples.append(data.Example.fromlist([None, texta, textb, None], fields))\n",
    "    else: # 训练集\n",
    "        for texta, textb, label in zip(csv_data['texta'], csv_data['textb'], csv_data['label']):\n",
    "            examples.append(data.Example.fromlist([None, texta, textb, label], fields))\n",
    "    return examples, fields\n",
    "\n",
    "train_examples,train_fields = get_dataset(pd_csv, TEXT, LABEL)\n",
    "\n",
    "train = data.Dataset(train_examples, train_fields)\n",
    "\n",
    "# 可以加载预训练数据\n",
    "'''\n",
    "pretrained_embedding = os.path.join(os.getcwd(), 'sgns.sogou.char')\n",
    "vectors = Vectors(name=pretrained_embedding)\n",
    "# 构建词典\n",
    "TEXT.build_vocab(train, min_freq=1, vectors = vectors)\n",
    "'''\n",
    "TEXT.build_vocab(train, min_freq=1)\n",
    "\n",
    "words_path = os.path.join(os.getcwd(), 'words.pkl')\n",
    "with open(words_path, 'wb') as f_words:\n",
    "    pickle.dump(TEXT.vocab, f_words)\n",
    "\n",
    "# 划分训练与验证集，一个问题，利用random_split进行数据集划分后，会丢失fields属性\n",
    "train_set, val_set = train.split(split_ratio=0.9, random_state=random.seed(1))\n",
    "    \n",
    "train_iter, val_iter = data.BucketIterator.splits(\n",
    "                                                (train_set, val_set),\n",
    "                                                batch_sizes=(64, len(val_set)),\n",
    "                                                shuffle=True,\n",
    "                                                # device=device,\n",
    "                                                sort_within_batch=True, #为true则一个batch内的数据会按sort_key规则降序排序\n",
    "                                                sort_key=lambda x: len(x.texta)) #这里按src的长度降序排序，主要是为后面pack,pad操作\n",
    "                                                # repeat=False\n",
    "print('dataset load done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "20\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#print(len(TEXT.vocab))\n",
    "print(train_iter.batch_size)\n",
    "print(val_iter.batch_size)\n",
    "print(TEXT.vocab.stoi['<pad>'])\n",
    "print(TEXT.vocab.stoi['<unk>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "tensor([[381, 360,  21,  ..., 421, 103, 229],\n",
      "        [120,  40,  53,  ...,  53, 118,  41],\n",
      "        [ 11,  33, 103,  ...,  11,  29,  22],\n",
      "        ...,\n",
      "        [  3,   2, 253,  ...,   1,   1,   1],\n",
      "        [ 11,  83,  27,  ...,   1,   1,   1],\n",
      "        [ 21,  15,   4,  ...,   1,   1,   1]])\n",
      "tensor([[ 21,  15,   4,  ...,   1,   1,   1],\n",
      "        [ 46,  40,  36,  ..., 100,  20,  65],\n",
      "        [ 11,  46,  24,  ...,   1,   1,   1],\n",
      "        ...,\n",
      "        [ 11,   3,   2,  ...,   1,   1,   1],\n",
      "        [ 11,  10,  32,  ...,   1,   1,   1],\n",
      "        [ 21,  15,   4,  ...,   1,   1,   1]])\n",
      "tensor([1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0,\n",
      "        1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1,\n",
      "        1, 1, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(train_iter))\n",
    "for b in train_iter:\n",
    "    print(b.texta)\n",
    "    print(b.textb)\n",
    "    print(b.label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 搭建模型\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hid_dim, n_layers, kernel_size, dropout, max_length=30):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        #for kernel in kernel_size:\n",
    "        assert kernel_size % 2 == 1,'kernel size must be odd!' # 卷积核size为奇数，方便序列两边pad处理\n",
    "        \n",
    "        self.scale = torch.sqrt(torch.FloatTensor([0.5])).to(DEVICE) # 确保整个网络的方差不会发生显著变化\n",
    "        \n",
    "        self.tok_embedding = nn.Embedding(input_dim, hid_dim) # token编码\n",
    "        self.pos_embedding = nn.Embedding(max_length, hid_dim) # token的位置编码\n",
    "        \n",
    "        #self.emb2hid = nn.Linear(emb_dim, hid_dim) # 线性层，从emb_dim转为hid_dim\n",
    "        #self.hid2emb = nn.Linear(hid_dim, emb_dim) # 线性层，从hid_dim转为emb_dim\n",
    "        \n",
    "        # 卷积块\n",
    "        \n",
    "        self.convs = nn.ModuleList([nn.Conv1d(in_channels=hid_dim,\n",
    "                                              out_channels=2*hid_dim, # 卷积后输出的维度，这里2*hid_dim是为了后面的glu激活函数\n",
    "                                              kernel_size=kernel_size,\n",
    "                                              padding=(kernel_size - 1)//2) # 序列两边补0个数，保持维度不变\n",
    "                                              for _ in range(n_layers)]) \n",
    "        \n",
    "        '''\n",
    "        利用不同size的卷积核进行特征提取\n",
    "        self.conv_1 = nn.ModuleList([nn.Conv1d(in_channels=hid_dim,\n",
    "                                                  out_channels=2*hid_dim, # 卷积后输出的维度，这里2*hid_dim是为了后面的glu激活函数\n",
    "                                                  kernel_size=kernel_size[0],\n",
    "                                                  padding=(kernel_size[0] - 1)//2) # 序列两边补0个数，保持维度不变\n",
    "                                                  for _ in range(n_layers)])\n",
    "        self.conv_2 = nn.ModuleList([nn.Conv1d(in_channels=hid_dim,\n",
    "                                                  out_channels=2*hid_dim, # 卷积后输出的维度，这里2*hid_dim是为了后面的glu激活函数\n",
    "                                                  kernel_size=kernel_size[1],\n",
    "                                                  padding=(kernel_size[1] - 1)//2) # 序列两边补0个数，保持维度不变\n",
    "                                                  for _ in range(n_layers)])\n",
    "        self.conv_3 = nn.ModuleList([nn.Conv1d(in_channels=hid_dim,\n",
    "                                                  out_channels=2*hid_dim, # 卷积后输出的维度，这里2*hid_dim是为了后面的glu激活函数\n",
    "                                                  kernel_size=kernel_size[2],\n",
    "                                                  padding=(kernel_size[2] - 1)//2) # 序列两边补0个数，保持维度不变\n",
    "                                                  for _ in range(n_layers)])\n",
    "        \n",
    "        # 几个卷积模块转换维度\n",
    "        self.convhid2hid = nn.Linear(len(kernel_size) * hid_dim, hid_dim)\n",
    "        '''\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src):\n",
    "        # src: [batch_size, src_len]\n",
    "        batch_size = src.shape[0]\n",
    "        src_len = src.shape[1]\n",
    "        \n",
    "        # 创建token位置信息\n",
    "        pos = torch.arange(src_len).unsqueeze(0).repeat(batch_size, 1).to(DEVICE) # [batch_size, src_len]\n",
    "        \n",
    "        # 对token与其位置进行编码\n",
    "        tok_embedded = self.tok_embedding(src) # [batch_size, src_len, emb_dim]\n",
    "        pos_embedded = self.pos_embedding(pos.long()) # [batch_size, src_len, emb_dim]\n",
    "        \n",
    "        # 对token embedded和pos_embedded逐元素加和\n",
    "        embedded = self.dropout(tok_embedded + pos_embedded) # [batch_size, src_len, emb_dim]\n",
    "        \n",
    "        # embedded经过一线性层，将emb_dim转为hid_dim，作为卷积块的输入\n",
    "        #conv_input = self.emb2hid(embedded) # [batch_size, src_len, hid_dim]\n",
    "        \n",
    "        # 转变维度，卷积在输入数据的最后一维进行\n",
    "        conv_input = embedded.permute(0, 2, 1) # [batch_size, hid_dim, src_len]\n",
    "        \n",
    "        \n",
    "        # 以下进行卷积块\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            # 进行卷积\n",
    "            conved = conv(self.dropout(conv_input)) # [batch_size, 2*hid_dim, src_len]\n",
    "            \n",
    "            # 进行激活glu\n",
    "            conved = F.glu(conved, dim=1) # [batch_size, hid_dim, src_len]\n",
    "            \n",
    "            # 进行残差连接\n",
    "            conved = (conved + conv_input) * self.scale # [batch_size, hid_dim, src_len]\n",
    "            \n",
    "            # 作为下一个卷积块的输入\n",
    "            conv_input = conved\n",
    "        \n",
    "        # 经过一线性层，将hid_dim转为emb_dim，作为enocder的卷积输出的特征\n",
    "        #conved = self.hid2emb(conved.permute(0, 2, 1)) # [batch_size, src_len, emb_dim]\n",
    "        \n",
    "        \n",
    "        \n",
    "        '''\n",
    "        利用不同size的卷积核进行特征提取\n",
    "        # 第一个kernel_size\n",
    "        conved_input = conv_input\n",
    "        for i, conv in enumerate(self.conv_1):\n",
    "            # 进行卷积\n",
    "            conved1 = conv(self.dropout(conved_input)) # [batch_size, 2*hid_dim, src_len]\n",
    "\n",
    "            # 进行激活glu\n",
    "            conved1 = F.glu(conved1, dim=1) # [batch_size, hid_dim, src_len]\n",
    "\n",
    "            # 进行残差连接\n",
    "            conved1 = (conved1 + conved_input) * self.scale # [batch_size, hid_dim, src_len]\n",
    "\n",
    "            # 作为下一个卷积块的输入\n",
    "            conved_input = conved1\n",
    "        \n",
    "        combine_conv_module = conved1\n",
    "        \n",
    "        # 第二个kernel_size\n",
    "        conved_input = conv_input\n",
    "        for i, conv in enumerate(self.conv_2):\n",
    "            # 进行卷积\n",
    "            conved2 = conv(self.dropout(conved_input)) # [batch_size, 2*hid_dim, src_len]\n",
    "\n",
    "            # 进行激活glu\n",
    "            conved2 = F.glu(conved2, dim=1) # [batch_size, hid_dim, src_len]\n",
    "\n",
    "            # 进行残差连接\n",
    "            conved2 = (conved2 + conved_input) * self.scale # [batch_size, hid_dim, src_len]\n",
    "\n",
    "            # 作为下一个卷积块的输入\n",
    "            conved_input = conved2\n",
    "            \n",
    "        combine_conv_module = torch.cat([combine_conv_module, conved2], dim = 1)\n",
    "        \n",
    "        # 第三个kernel_size\n",
    "        conved_input = conv_input\n",
    "        for i, conv in enumerate(self.conv_3):\n",
    "            # 进行卷积\n",
    "            conved3 = conv(self.dropout(conved_input)) # [batch_size, 2*hid_dim, src_len]\n",
    "\n",
    "            # 进行激活glu\n",
    "            conved3 = F.glu(conved3, dim=1) # [batch_size, hid_dim, src_len]\n",
    "\n",
    "            # 进行残差连接\n",
    "            conved3 = (conved3 + conved_input) * self.scale # [batch_size, hid_dim, src_len]\n",
    "\n",
    "            # 作为下一个卷积块的输入\n",
    "            conved_input = conved3\n",
    "            \n",
    "        combine_conv_module = torch.cat([combine_conv_module, conved3], dim = 1)\n",
    "        \n",
    "        conved = self.convhid2hid(combine_conv_module.permute(0, 2, 1)) # [batch_size, src_len, hid_dim]\n",
    "        '''\n",
    "        \n",
    "        # 又是一个残差连接，逐元素加和输出，作为encoder的联合输出特征\n",
    "        combined = (conved.permute(0, 2, 1) + embedded) * self.scale # [batch_size, src_len, emb_dim]\n",
    "        \n",
    "        return conved, combined\n",
    "\n",
    "'''\n",
    "多头注意力multi-head attention\n",
    "'''\n",
    "class MultiHeadAttentionLayer(nn.Module):\n",
    "    def __init__(self, hid_dim, n_heads, dropout):\n",
    "        super(MultiHeadAttentionLayer, self).__init__()\n",
    "        \n",
    "        assert hid_dim % n_heads == 0\n",
    "        \n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_heads = n_heads\n",
    "        self.head_dim = hid_dim // n_heads\n",
    "        \n",
    "        self.fc_q = nn.Linear(hid_dim, hid_dim)\n",
    "        self.fc_k = nn.Linear(hid_dim, hid_dim)\n",
    "        self.fc_v = nn.Linear(hid_dim, hid_dim)\n",
    "        \n",
    "        self.fc_o = nn.Linear(hid_dim, hid_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.scale = torch.sqrt(torch.FloatTensor([self.hid_dim])).to(DEVICE) # 缩放因子\n",
    "        \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        '''\n",
    "        query: [batch_size, query_len, hid_dim]\n",
    "        key: [batch_size, key_len, hid_dim]\n",
    "        value: [batch_size, value_len, hid_dim]\n",
    "        '''\n",
    "        batch_size = query.shape[0]\n",
    "        \n",
    "        Q = self.fc_q(query) # [batch_size, query_len, hid_dim]\n",
    "        K = self.fc_k(key) # [batch_size, key_len, hid_dim]\n",
    "        V = self.fc_v(value) # [batch_size, value_len, hid_dim]\n",
    "        \n",
    "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3) # [batch_size, n_heads, query_len, head_dim]\n",
    "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3) # [batch_size, n_heads, key_len, head_dim]\n",
    "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3) # [batch_size, n_heads, value_len, head_dim]\n",
    "        \n",
    "        # [batch_size, n_heads, query_len, head_dim] * [batch_size, n_heads, head_dim, key_len]\n",
    "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale # [batch_size, n_heads, query_len, key_len]\n",
    "        \n",
    "        if mask != None:\n",
    "            energy = energy.masked_fill(mask == 0, -1e10)\n",
    "        \n",
    "        attention = torch.softmax(energy, dim=-1) # [batch_size, n_heads, query_len, key_len]\n",
    "        \n",
    "        # [batch_size, n_heads, query_len, key_len] * [batch_size, n_heads, value_len, head_dim]\n",
    "        x = torch.matmul(self.dropout(attention), V) # [batch_size, n_heads, query_len, head_dim]\n",
    "        \n",
    "        x = x.permute(0, 2, 1, 3).contiguous() # [batch_size, query_len, n_heads, head_dim]\n",
    "        \n",
    "        x = x.view(batch_size, -1, self.hid_dim) # [batch_size, query_len, hid_dim]\n",
    "        \n",
    "        x = self.fc_o(x) # [batch_size, query_len, hid_dim]\n",
    "        \n",
    "        return x, attention\n",
    "    \n",
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self, EncoderA, hid_dim, n_heads, dropout):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.EncoderA = EncoderA\n",
    "        #self.EncoderB = EncoderB\n",
    "        #self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # 多头\n",
    "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout)\n",
    "        \n",
    "        self.fcA = nn.Linear(2 * hid_dim, hid_dim)\n",
    "        self.fcB = nn.Linear(2 * hid_dim, hid_dim)\n",
    "        \n",
    "        self.fc_out = nn.Linear(5 * hid_dim, 2)\n",
    "        \n",
    "    def calculate_attention(self, convedA, convedB):\n",
    "        '''\n",
    "        convedA:[batch_size, len, hid_dim]\n",
    "        convedB:[batch_size, len, hid_dim]\n",
    "        '''\n",
    "        energy = torch.matmul(convedA, convedB.permute(0, 2, 1)) # [batch_size, trg_len, src_len]\n",
    "        \n",
    "        attention = F.softmax(energy, dim=2) # [batch_size, trg_len, src_len]\n",
    "        \n",
    "        attention_encoding = torch.matmul(attention, convedB) # [batch_size, trg_len, hid_dim]\n",
    "        \n",
    "        return attention, attention_encoding\n",
    "    \n",
    "    def forward(self, sentA, sentB):\n",
    "        convedA, combinedA = self.EncoderA(sentA)\n",
    "        convedB, combinedB = self.EncoderA(sentB)\n",
    "        \n",
    "        # 普通attention\n",
    "        #attentionA, attended_encodingA = self.calculate_attention(combinedB, combinedA)\n",
    "        #attentionB, attended_encodingB = self.calculate_attention(combinedA, combinedB)\n",
    "        \n",
    "        # 多头attention，来自transformer模型中\n",
    "        self_attentionA, attentionA = self.self_attention(combinedB, combinedA, combinedA)\n",
    "        self_attentionB, attentionB = self.self_attention(combinedA, combinedB, combinedB)\n",
    "        \n",
    "        combinedA = torch.cat([self_attentionA, combinedA], dim=2) # [batch_size, len, 2 * hid_dim]\n",
    "        combinedB = torch.cat([self_attentionB, combinedB], dim=2) # [batch_size, len, 2 * hid_dim]\n",
    "        \n",
    "        combinedA = self.fcA(combinedA) # [batch_size, len, hid_dim]\n",
    "        combinedB = self.fcB(combinedB) # [batch_size, len, hid_dim]\n",
    "        \n",
    "        combinedA = F.avg_pool1d(combinedA.permute(0, 2, 1), combinedA.shape[1]).squeeze(2) # [batch_size, emb_dim]\n",
    "        combinedB = F.avg_pool1d(combinedB.permute(0, 2, 1), combinedB.shape[1]).squeeze(2) # [batch_size, emb_dim]\n",
    "\n",
    "        similarity = torch.cosine_similarity(combinedA, combinedB, dim=1) # 直接计算和学习相似度\n",
    "        \n",
    "        # 以下是做二分类\n",
    "        # [p, q, p+q, p-q, p*q]\n",
    "        #fc_out = self.fc_out(torch.cat([combinedA, combinedB, combinedA+combinedB, combinedA-combinedB, combinedA*combinedB], dim=1)) # 【batch_size, 2】\n",
    "        \n",
    "        return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对所有模块和子模块进行权重初始化\n",
    "def init_weights(model):\n",
    "    for name,param in model.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "定义model\n",
    "'''\n",
    "\n",
    "input_dim = len(TEXT.vocab)\n",
    "emb_dim = 128\n",
    "cnn_layers = 4 # Encoder中几层卷积块\n",
    "kernel_size = 3 #(3,5,7)\n",
    "dropout = 0.5\n",
    "n_heads = 4\n",
    "\n",
    "pad_idx = TEXT.vocab.stoi['<pad>']\n",
    "\n",
    "encA = Encoder(input_dim, emb_dim, cnn_layers, kernel_size, dropout) # source与target共享encoder，也可分开定义不同的encoder\n",
    "\n",
    "#encB = Encoder(input_dim, emb_dim, cnn_layers, kernel_size, dropout)\n",
    "\n",
    "model = SiameseNetwork(encA, emb_dim, n_heads, dropout).to(DEVICE)\n",
    "\n",
    "# 对所有模块和子模块进行权重初始化\n",
    "# model.apply(init_weights)\n",
    "\n",
    "'''\n",
    "在已训练的model基础上再训练\n",
    "model_path = os.path.join(os.getcwd(), \"model.h5\")\n",
    "if os.path.exists(model_path):\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    print('model load done!')\n",
    "'''\n",
    "\n",
    "# 优化函数\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "# optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# 损失函数\n",
    "#分类\n",
    "# criterion = nn.BCELoss() # 和sigmoid结合使用\n",
    "# criterion = nn.BCEWithLogitsLoss() # sigmoid + bceloss\n",
    "# 不平衡类加权\n",
    "#weight = torch.tensor([0.1, 1.0])\n",
    "#weight = weight.to(DEVICE)\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
    "\n",
    "#回归，用于相似度\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# 训练\n",
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    \n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i, batch in enumerate(iterator):\n",
    "        \n",
    "        texta = batch.texta  # src=[batch_size, seq_len]\n",
    "        textb = batch.textb  # trg=[batch_size, seq_len]\n",
    "        label = batch.label # [batch_size]\n",
    "        \n",
    "        texta = texta.to(DEVICE)\n",
    "        textb = textb.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        out = model(texta, textb) # [batch_size, 2]\n",
    "        # 计算loss\n",
    "        loss = criterion(out, label.float())\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "# val loss\n",
    "def evaluate(model, iterator, criterion):\n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(iterator):\n",
    "            texta = batch.texta  # src=[batch_size, seq_len]\n",
    "            textb = batch.textb  # trg=[batch_size, seq_len]\n",
    "            label = batch.label # [batch_size]\n",
    "\n",
    "            texta = texta.to(DEVICE)\n",
    "            textb = textb.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "            \n",
    "            out = model(texta, textb) # [batch_size, 2]\n",
    "            \n",
    "            # 分类的评估auc score\n",
    "            '''\n",
    "            prediction = torch.max(F.softmax(out, dim=1), dim=1)[1]\n",
    "            \n",
    "            pred_y = prediction.cpu().data.numpy().squeeze()\n",
    "            target_y = label.cpu().data.numpy()\n",
    "            score = roc_auc_score(target_y, pred_y)\n",
    "            '''\n",
    "            # 计算loss\n",
    "            loss = criterion(out, label.float())\n",
    "        \n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 0m 0s\n",
      "\tTrain Loss: 0.365 | Train PPL:   1.440\n",
      "\t Val. Loss: 0.254 |  Val. PPL:   1.289\n",
      "Epoch: 02 | Time: 0m 0s\n",
      "\tTrain Loss: 0.256 | Train PPL:   1.292\n",
      "\t Val. Loss: 0.278 |  Val. PPL:   1.321\n",
      "Epoch: 03 | Time: 0m 0s\n",
      "\tTrain Loss: 0.242 | Train PPL:   1.274\n",
      "\t Val. Loss: 0.288 |  Val. PPL:   1.333\n",
      "Epoch: 04 | Time: 0m 0s\n",
      "\tTrain Loss: 0.239 | Train PPL:   1.270\n",
      "\t Val. Loss: 0.301 |  Val. PPL:   1.352\n",
      "Epoch: 05 | Time: 0m 0s\n",
      "\tTrain Loss: 0.248 | Train PPL:   1.281\n",
      "\t Val. Loss: 0.321 |  Val. PPL:   1.378\n",
      "Epoch: 06 | Time: 0m 0s\n",
      "\tTrain Loss: 0.246 | Train PPL:   1.279\n",
      "\t Val. Loss: 0.291 |  Val. PPL:   1.337\n",
      "Epoch: 07 | Time: 0m 0s\n",
      "\tTrain Loss: 0.232 | Train PPL:   1.261\n",
      "\t Val. Loss: 0.311 |  Val. PPL:   1.364\n",
      "Epoch: 08 | Time: 0m 0s\n",
      "\tTrain Loss: 0.216 | Train PPL:   1.241\n",
      "\t Val. Loss: 0.342 |  Val. PPL:   1.408\n",
      "Epoch: 09 | Time: 0m 0s\n",
      "\tTrain Loss: 0.226 | Train PPL:   1.253\n",
      "\t Val. Loss: 0.325 |  Val. PPL:   1.385\n",
      "Epoch: 10 | Time: 0m 0s\n",
      "\tTrain Loss: 0.201 | Train PPL:   1.223\n",
      "\t Val. Loss: 0.328 |  Val. PPL:   1.388\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10 # 迭代次数 \n",
    "clip = 0.1 # 梯度裁剪\n",
    "import math\n",
    "\n",
    "model_path = os.path.join(os.getcwd(), \"model.h5\")\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_iter, optimizer, criterion, clip)\n",
    "    valid_loss = evaluate(model, val_iter, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time) # 每个epoch花费的时间\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
    "    # print(f'\\t Val. auc_score: {score:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
